@comment{

Este es el archivo de referencias bibliogr'aficas, que incluye tambi'en algunos
ejemplos de c'omo capturar la informaci'on de tus referencias.

Algunas de las referencias m'as comunes son art'iculos de revista,
estos se escriben como se muestra acontinuaci'on. Nota que los nombres
de los autores se separan siempre por la palabra " and ", *incluso* si el
documento de tesis est'a escrito en espa~nol. El sistema cambiara ese "and"
por el apropiado "y".

}

@article {Ledoit,
	author = {Ledoit, Olivier and Wolf, Michael},
	title = {Honey, I Shrunk the Sample Covariance Matrix},
	volume = {30},
	number = {4},
	pages = {110--119},
	year = {2004},
	doi = {10.3905/jpm.2004.110},
	publisher = {Institutional Investor Journals Umbrella},
	abstract = {The central message of this article is that no one should use the sample covariance matrix for portfolio optimization. It is subject to estimation error of the kind most likely to perturb a mean-variance optimizer. Instead, a matrix can be obtained from the sample covariance matrix through a transformation called shrinkage. This tends to pull the most extreme coefficients toward more central values, systematically reducing estimation error when it matters most. Statistically, the challenge is to know the optimal shrinkage intensity. Shrinkage reduces portfolio tracking error relative to a benchmark index, and substantially raises the manager{\textquoteright}s realized information ratio.},
	issn = {0095-4918},
	URL = {https://jpm.iijournals.com/content/30/4/110},
	eprint = {https://jpm.iijournals.com/content/30/4/110.full.pdf},
	journal = {The Journal of Portfolio Management}
}

@article{Ledoit2008,
  author={Ledoit, Oliver and Wolf, Michael},
  title={{Robust performance hypothesis testing with the Sharpe ratio}},
  journal={Journal of Empirical Finance},
  year=2008,
  volume={15},
  number={5},
  pages={850-859},
  month={December},
  keywords={ Bootstrap HAC inference Sharpe ratio},
  doi={},
  abstract={Applied researchers often test for the difference of the Sharpe ratios of two investment strategies. A very popular tool to this end is the test of Jobson and Korkie [Jobson, J.D. and Korkie, B.M. (1981). Performance hypothesis testing with the Sharpe and Treynor measures. Journal of Finance, 36:889-908], which has been corrected by Memmel [Memmel, C. (2003). Performance hypothesis testing with the Sharpe ratio. Finance Letters, 1:21-23]. Unfortunately, this test is not valid when returns have tails heavier than the normal distribution or are of time series nature. Instead, we propose the use of robust inference methods. In particular, we suggest to construct a studentized time series bootstrap confidence interval for the difference of the Sharpe ratios and to declare the two ratios different if zero is not contained in the obtained interval. This approach has the advantage that one can simply resample from the observed data as opposed to some null-restricted data. A simulation study demonstrates the improved finite sample performance compared to existing methods. In addition, two applications to real data are provided.},
  url={https://ideas.repec.org/a/eee/empfin/v15y2008i5p850-859.html}
}


@article{Markowitz,
 ISSN = {00221082, 15406261},
 URL = {http://www.jstor.org/stable/2975974},
 author = {Harry Markowitz},
 journal = {The Journal of Finance},
 number = {1},
 pages = {77--91},
 publisher = {[American Finance Association, Wiley]},
 title = {Portfolio Selection},
 volume = {7},
 year = {1952}
}

@article{Sharpe,
 ISSN = {00221082, 15406261},
 URL = {http://www.jstor.org/stable/2977928},
 author = {William F. Sharpe},
 journal = {The Journal of Finance},
 number = {3},
 pages = {425--442},
 publisher = {[American Finance Association, Wiley]},
 title = {Capital Asset Prices: A Theory of Market Equilibrium under Conditions of Risk},
 volume = {19},
 year = {1964}
}

@article{Resampling,
 ISSN = {0015198X},
 URL = {http://www.jstor.org/stable/4480438},
 abstract = {A well-understood fact of asset allocation is that the traditional portfolio optimization algorithm is too powerful for the quality of the inputs. Recently, a new concept called "resampled efficiency" has been introduced into the asset management world to deal with estimation error. The objective of this article is to describe this new technology, put it into the context of established procedures, and point to some peculiarities of the approach. Even though portfolio resampling is a thoughtful heuristic, some features make it difficult to interpret by the inexperienced.},
 author = {Bernd Scherer},
 journal = {Financial Analysts Journal},
 number = {6},
 pages = {98--109},
 publisher = {CFA Institute},
 title = {Portfolio Resampling: Review and Critique},
 volume = {58},
 year = {2002}
}

@Article{Worst1,
author="T{\"u}t{\"u}nc{\"u}, R.H.
and Koenig, M.",
title="Robust Asset Allocation",
journal="Annals of Operations Research",
year="2004",
month="Nov",
day="01",
volume="132",
number="1",
pages="157--187",
abstract="This article addresses the problem of finding an optimal allocation of funds among different asset classes in a robust manner when the estimates of the structure of returns are unreliable. Instead of point estimates used in classical mean-variance optimization, moments of returns are described using uncertainty sets that contain all, or most, of their possible realizations. The approach presented here takes a conservative viewpoint and identifies asset mixes that have the best worst-case behavior. Techniques for generating uncertainty sets from historical data are discussed and numerical results that illustrate the stability of robust optimal asset mixes are reported.",
issn="1572-9338",
doi="10.1023/B:ANOR.0000045281.41041.ed",
url="https://doi.org/10.1023/B:ANOR.0000045281.41041.ed"
}

@article{Black1,
author = {Walters, Jay},
year = {2011},
month = {07},
pages = {},
title = {The Black-Litterman Model in Detail},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.1314585}
}

@Article{Ross,
  author={Ross, Stephen A.},
  title={{The arbitrage theory of capital asset pricing}},
  journal={Journal of Economic Theory},
  year=1976,
  volume={13},
  number={3},
  pages={341-360},
  month={December},
  keywords={},
  doi={},
  abstract={No abstract is available for this item.},
  url={https://ideas.repec.org/a/eee/jetheo/v13y1976i3p341-360.html}
}


@Article{Fan,
  author={Fan, Jianqing and Fan, Yingying and Lv, Jinchi},
  title={{High dimensional covariance matrix estimation using a factor model}},
  journal={Journal of Econometrics},
  year=2008,
  volume={147},
  number={1},
  pages={186-197},
  month={November},
  keywords={ Factor model Diverging dimensionality Covariance matrix estimation Asymptotic properties Portfolio },
  doi={},
  abstract={High dimensionality comparable to sample size is common in many statistical problems. We examine covariance matrix estimation in the asymptotic framework that the dimensionality p tends to [infinity] as the sample size n increases. Motivated by the Arbitrage Pricing Theory in finance, a multi-factor model is employed to reduce dimensionality and to estimate the covariance matrix. The factors are observable and the number of factors K is allowed to grow with p. We investigate the impact of p and K on the performance of the model-based covariance matrix estimator. Under mild assumptions, we have established convergence rates and asymptotic normality of the model-based estimator. Its performance is compared with that of the sample covariance matrix. We identify situations under which the factor approach increases performance substantially or marginally. The impacts of covariance matrix estimation on optimal portfolio allocation and portfolio risk assessment are studied. The asymptotic results are supported by a thorough simulation study.},
  url={https://ideas.repec.org/a/eee/econom/v147y2008i1p186-197.html}
}

@article{Charnes,
author = {Charnes, A. and Cooper, W. W.},
title = {Programming with linear fractional functionals},
journal = {Naval Research Logistics Quarterly},
volume = {9},
number = {3‐4},
pages = {181-186},
doi = {10.1002/nav.3800090303},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/nav.3800090303},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/nav.3800090303},
year = {1962}
}


@Article{FamaFrench,
    author = {Eugene F. Fama and Kenneth R. French},
    title = {Common Risk Factors in the Returns On Stocks And Bonds},
    journal = {Journal of Financial Economics},
    year = {1993},
    volume = {33},
    pages = {3--56}
}

@article{Michaud1989,
 ISSN = {0015198X},
 URL = {http://www.jstor.org/stable/4479185},
 abstract = {The indifference of many investment practitioners to mean-variance optimization technology, despite its theoretical appeal, is understandable in many cases. The major problem with MV optimization is its tendency to maximize the effects of errors in the input assumptions. Unconstrained MV optimization can yield results that are inferior to those of simple equal-weighting schemes. Nevertheless, MV optimization is superior to many ad hoc techniques in terms of integration of portfolio objectives with client constraints and efficient use of information. Its practical value may be enhanced by the sophisticated adjustment of inputs and the imposition of constraints based on fundamental investment considerations and the importance of priors. The operating principle should be that, to the extent that reliable information is available, it should be included as part of the definition of the optimization procedure.},
 author = {Richard O. Michaud},
 journal = {Financial Analysts Journal},
 number = {1},
 pages = {31--42},
 publisher = {CFA Institute},
 title = {The Markowitz Optimization Enigma: Is 'Optimized' Optimal?},
 volume = {45},
 year = {1989}
}

@article{Michaud1998,
author = {Michaud, Richard and Michaud, Robert},
year = {2007},
month = {01},
pages = {pp. 8 - 28},
title = {Estimation Error and Portfolio Optimization: A Resampling Solution},
volume = {Vol. 6},
journal = {Journal of Investment Management}
}

@article{Green,
 ISSN = {00221082, 15406261},
 URL = {http://www.jstor.org/stable/2328996},
 abstract = {We characterize the conditions under which efficient portfolios put small weights on individual assets. These conditions bound mean returns with measures of average absolute covariability between assets. The bounds clarify the relationship between linear asset pricing models and well-diversified efficient portfolios. We argue that the extreme weightings in sample efficient portfolios are due to the dominance of a single factor in equity returns. This makes it easy to diversify on subsets to reduce residual risk, while weighting the subsets to reduce factor risk simultaneously. The latter involves taking extreme positions. This behavior seems unlikely to be attributable to sampling error.},
 author = {Richard C. Green and Burton Hollifield},
 journal = {The Journal of Finance},
 number = {5},
 pages = {1785--1809},
 publisher = {[American Finance Association, Wiley]},
 title = {When Will Mean-Variance Efficient Portfolios be Well Diversified?},
 volume = {47},
 year = {1992}
}


@article{DeMiguel2009,
 author = {DeMiguel, Victor and Nogales, Francisco J.},
 title = {Portfolio Selection with Robust Estimation},
 journal = {Oper. Res.},
 issue_date = {May 2009},
 volume = {57},
 number = {3},
 month = may,
 year = {2009},
 issn = {0030-364X},
 pages = {560--577},
 numpages = {18},
 url = {https://doi.org/10.1287/opre.1080.0566},
 doi = {10.1287/opre.1080.0566},
 acmid = {1556420},
 publisher = {INFORMS},
 address = {Institute for Operations Research and the Management Sciences (INFORMS), Linthicum, Maryland, USA},
 keywords = {econometrics, economics, estimation error, finance, investment, minimum-variance portfolios, portfolio, portfolio choice, robust statistics},
} 

@article{DeMiguel20092,
author = {Demiguel, Victor and Garlappi, Lorenzo and Uppal, Raman},
year = {2009},
month = {05},
pages = {},
title = {Optimal Versus Naive Diversification: How Inefficient is the 1/N Portfolio Strategy?},
volume = {22},
journal = {Review of Financial Studies},
doi = {10.1093/rfs/hhm075}
}

@article{Santos,
author = {Santos, André},
year = {2010},
month = {07},
pages = {},
title = {The Out-of-Sample Performance of Robust Portfolio Optimization},
volume = {8},
journal = {Revista Brasileira de Finanças}
}

@Article{Hawawini,
  author={Gabriel A. Hawawini},
  title={{The Intertemporal Cross Price Behavior of Common Stocks: Evidence and Implications}},
  journal={Journal of Financial Research},
  year=1980,
  volume={3},
  number={2},
  pages={153-167},
  month={June},
  keywords={},
  doi={},
  abstract={The paper presents a measure of the intertemporal cross correlation between two time series and reports evidence of the presence of intertemporal cross dependence between the returns of NYSE stocks and those of the SP 500, showing that frequently traded stocks behave differently from stocks with thinner markets.<br><small>(This abstract was borrowed from another version of this item.)</small>},
  url={https://ideas.repec.org/a/bla/jfnres/v3y1980i2p153-167.html}
}



@TechReport{Ledoit2010,
  author={Olivier Ledoit and Michael Wolf},
  title={{Robust performance hypothesis testing with the variance}},
  year=2010,
  month=Oct,
  institution={Institute for Empirical Research in Economics - University of Zurich},
  type={IEW - Working Papers},
  url={https://ideas.repec.org/p/zur/iewwpx/516.html},
  number={516},
  abstract={Applied researchers often test for the difference of the variance of two investment strategies; in particular, when the investment strategies under consideration aim to implement the global minimum variance portfolio. A popular tool to this end is the F-test for the equality of variances. Unfortunately, this test is not valid when the returns are correlated, have tails heavier than the normal distribution, or are of time series nature. Instead, we propose the use of robust inference methods. In particular, we suggest to construct a studentized time series bootstrap confidence interval for the ratio of the two variances and to declare the two variances different if the value one is not contained in the obtained interval. This approach has the advantage that one can simply resample from the observed data as opposed to some null-restricted data. A simulation study demonstrates the improved finite-sample performance compared to existing methods.},
  keywords={Bootstrap; HAC inference; Variance},
  doi={},
}

@TechReport{Ledoit2018,
  author={Olivier Ledoit and Michael Wolf},
  title={{Robust performance hypothesis testing with smooth functions of population moments}},
  year=2018,
  month=Oct,
  institution={Department of Economics - University of Zurich},
  type={ECON - Working Papers},
  url={https://ideas.repec.org/p/zur/econwp/305.html},
  number={305},
  abstract={Applied researchers often want to make inference for the difference of a given performance measure for two investment strategies. In this paper, we consider the class of performance measures that are smooth functions of population means of the underlying returns; this class is very rich and contains many performance measures of practical interest (such as the Sharpe ratio and the variance). Unfortunately, many of the inference procedures that have been suggested previously in the applied literature make unreasonable assumptions that do not apply to real-life return data, such as normality and independence over time. We will discuss inference procedures that are asymptotically valid under very general conditions, allowing for heavy tails and time dependence in the return data. In particular, we will promote a studentized time series bootstrap procedure. A simulation study demonstrates the improved finite-sample performance compared to existing procedures. Applications to real data are also provided.},
  keywords={Bootstrap; HAC inference; kurtosis; Sharpe ratio; sknewness; variance},
  doi={},
}

@article{Konno,
title = {Mean-Absolute Deviation Portfolio Optimization Model and Its Applications to Tokyo Stock Market},
author = {Konno, Hiroshi and Yamazaki, Hiroaki},
year = {1991},
journal = {Management Science},
volume = {37},
number = {5},
pages = {519-531},
abstract = {The purpose of this paper is to demonstrate that a portfolio optimization model using the L 1 risk (mean absolute deviation risk) function can remove most of the difficulties associated with the classical Markowitz's model while maintaining its advantages over equilibrium models. In particular, the L 1 risk model leads to a linear program instead of a quadratic program, so that a large-scale optimization problem consisting of more than 1,000 stocks may be solved on a real time basis. Numerical experiments using the historical data of NIKKEI 225 stocks show that the L 1 risk model generates a portfolio quite similar to that of the Markowitz's model within a fraction of time required to solve the latter.},
keywords = {portfolio optimization; L1 risk function; linear programming; Markowitz's model; single-factor model},
url = {https://EconPapers.repec.org/RePEc:inm:ormnsc:v:37:y:1991:i:5:p:519-531}
}

@article{Rockafellar,
    author = {R. Tyrrell Rockafellar and Stanislav Uryasev},
    title = {Optimization of Conditional Value-at-Risk},
    journal = {Journal of Risk},
    year = {2000},
    volume = {2},
    pages = {21--41}
}

@InCollection{Uryasev1,
  author={A. Chekhlov and S. Uryasev and M. Zabarankin},
  editor={Panos M Pardalos and Athanasios Migdalas and George Baourakis},
  title={{Portfolio Optimization With Drawdown Constraints}},
  booktitle={{Supply Chain And Finance}},
  publisher={World Scientific Publishing Co. Pte. Ltd.},
  year=2004,
  month={November},
  volume={},
  number={},
  series={World Scientific Book Chapters},
  edition={},
  chapter={13},
  pages={209-228},
  keywords={Finance; Supply Chain; E-Commerce; Optimization; Mathematical Modeling; Operations Research},
  abstract={AbstractWe propose a new one-parameter family of risk measures, which is called Conditional Draw-down-at-Risk (CDaR). These measures of risk are functionals of the portfolio drawdown (underwater) curve considered in an active portfolio management. For some value of the tolerance parameter β, the CDaR is defined as the mean of the worst (1 - β) * 100\% drawdowns. The CDaR risk measure includes the Maximal Drawdown and Average Drawdown as its limiting cases. For a particular example, we find the optimal portfolios for a case of Maximal Drawdown, a case of Average Drawdown, and several intermediate cases between these two. The CDaR family of risk measures is similar to Conditional Value-at-Risk (CVaR), which is also called Mean Shortfall, Mean Access loss, or Tail Value-at-Risk. Some recommendations on how to select the optimal risk measure for getting practically stable portfolios are provided. We solved a real life portfolio allocation problem using the proposed measures.},
  url={https://ideas.repec.org/h/wsi/wschap/9789812562586_0013.html}
}


@inproceedings{Uryasev2,
  title={Drawdown Measure in Portfolio Optimization},
  author={Alexei Chekhlov and S. P. Uryasev and Michael Zabarankin},
  year={2005}
}

@inbook{Mansini1,
author = {Mansini, Renata and Ogryczak, W. and Speranza, M.Grazia},
year = {2015},
month = {01},
pages = {19-45},
title = {Linear Models for Portfolio Optimization},
publisher = {Springer},
isbn = {978-3-319-18481-4},
doi = {10.1007/978-3-319-18482-1_2}

}

@article{Mansini2,
author = {Mansini, Renata and Ogryczak, W. and Speranza, M.Grazia},
year = {2003},
month = {01},
pages = {37-62},
title = {On LP Solvable Models for Portfolio Selection},
volume = {14},
journal = {Informatica}
}

@article{Mansini3,
author = {Mansini, Renata and Ogryczak, W. and Speranza, M.Grazia},
year = {2014},
month = {04},
pages = {518-535},
title = {Twenty years of linear programming based portfolio optimization},
volume = {234},
journal = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2013.08.035}
}

@comment{

Los que siguen son ejemplos de libros.

}

@book{Knuth84,
	Author = {Donald E. Knuth},
	Publisher = {Addison-Wesley},
	Title = {The {\TeX}book},
	Year = 1984}

@book{Lamport86,
	Author = {Leslie Lamport},
	Publisher = {Addison-Wesley},
	Title = {{\LaTeX}: A Document Preparation System},
	Year = 1986}

@book{Fabozzi,
	author = {J Fabozzi, Frank and Kolm, Petter and Pachamanova, Dessislava and Focardi, Sergio},
	year = {2007},
	month = {05},
	pages = {},
	title = {Robust Portfolio Optimization and Management}
}

@book{Boyd,
place={Cambridge},
title={Convex Optimization},
DOI={10.1017/CBO9780511804441},
publisher={Cambridge University Press},
author={Boyd, Stephen and Vandenberghe, Lieven},
year={2004}}

@book{MichaudBook,
author = {Michaud, Richard and Michaud, Robert},
year = {2008},
month = {01},
pages = {},
title = {Efficient Asset Management: A Practical Guide to Stock Portfolio Optimization and Asset Allocation}
}

@book{Mansini,
author = {Mansini, Renata and Ogryczak, W. and Speranza, M.Grazia},
year = {2015},
month = {01},
pages = {1-119},
title = {Linear and Mixed Integer Programming for Portfolio Optimization},
journal = {Linear and Mixed Integer Programming for Portfolio Optimization},
doi = {10.1007/978-3-319-18482-1}
}

@comment{

Ahora un ejemplo de un art'iculo publicado en un congreso. Nota tambi'en
que, a'un cuando son varios autores, tienes que escribir *siempre* la
palabra " and " entre cada par de ellos.

}

@inproceedings{Rofl06,
	Author = {Matthew Caesar and Tyson Condie and Jayanthkumar Kannan
	          and Karthik Lakshminarayanan and Ion Stoica},
	Booktitle = {ACM SIGCOMM},
	Title = {{ROFL}: Routing on Flat Labels},
	Year = {2006}}

@comment{

Finalmente dos referencias a manuales.

}

@misc{Wolf,
author = {Michael Wolf},
title = {Publications},
year = {2008},
howpublished = {\url{https://www.econ.uzh.ch/en/people/faculty/wolf/publications.html}},
urldate = {15-07-2019}
}

@manual{doc:natbib,
	Author = {Patrick W. Daly},
	Month = feb,
	Title = {Naural Sciences Citations and References},
	Year = {2007}}

@manual{doc:geometry,
	Author = {Hideo Umeki},
	Month = jul,
	Title = {The geometry package},
	Year = {2002}}

@comment{

Referencias a tesis

}

@mastersthesis{Graaf,
  author       = {T.A. de Graaf}, 
  title        = {Robust Mean-Variance Optimization},
  school       = {Leiden University},
  year         = 2016,
  address      = {Rapenburg 70, 2311 EZ Leiden, Netherlands},
  month        = 12,
  url={https://www.universiteitleiden.nl/binaries/content/assets/science/mi/scripties/master/de_graaf_tanita_master.pdf},

}

@mastersthesis{Cajas,
  author       = {Dany Cajas},
  title        = {Optimización Robusta de Portafolios mediante Near Optimal Centering},
  school       = {Universidad Nacional de Ingenieria},
  type = {Tesis de Título Profesional},
  note = {unpublished thesis},  
  year         = 2019,
  address      = {Avenida Tupac Amaru 210 Apartado 1301, Rímac, Lima, Perú},
  month        = 12,
}

@article{BlackLitterman,
 ISSN = {0015198X},
 URL = {http://www.jstor.org/stable/4479577},
 abstract = {Quantitative asset allocation models have not played the important role they should in global portfolio management. A good part of the problem is that such models are difficult to use and tend to result in portfolios that are badly behaved. Consideration of the global CAPM equilibrium can significantly improve the usefulness of these models. In particular, equilibrium returns for equities, bonds and currencies provide neutral starting points for estimating the set of expected excess returns needed to drive the portfolio optimization process. This set of neutral weights can then be tilted in accordance with the investor's views. If the investor has no particular views about asset returns, he can use the neutral values given by the equilibrium model. If the investor does have one or more views about the relative performances of assets, or their absolute performances, he can adjust equilibrium values in accordance with those views. Furthermore, the investor can control how strongly a particular view influences portfolio weights, in accordance with the degree of confidence with which he holds the view.},
 author = {Fischer Black and Robert Litterman},
 journal = {Financial Analysts Journal},
 number = {5},
 pages = {28--43},
 publisher = {CFA Institute},
 title = {Global Portfolio Optimization},
 volume = {48},
 year = {1992}
}

@article{transaction,
author = {Trzcinka, Charles and Lesmond, David and Ogden, Joseph},
year = {1999},
month = {02},
pages = {1113-41},
title = {A New Estimate of Transaction Costs},
volume = {12},
journal = {Review of Financial Studies}
}

@article{Roncalli,
author = {Bruder, Benjamin and Roncalli, Thierry},
year = {2012},
month = {01},
pages = {},
title = {Managing Risk Exposures Using the Risk Budgeting Approach},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.2009778}
}

@Book{fabozzi2007robust,
 author = {Fabozzi, Frank},
 title = {Robust portfolio optimization and management},
 publisher = {John Wiley},
 year = {2007},
 address = {Hoboken, N.J},
 isbn = {978-0-471-92122-6}
 }

@misc{Lobo,
author = {Sousa Lobo, Miguel and Boyd, Stephen},
year = {2000},
month = {10},
title = {The worst-case risk of a portfolio}
}

@article{Tutuncu,
author = {Tütüncü, R.H. and Koenig, M.},
year = {2004},
month = {01},
pages = {157-187},
title = {Robust Asset Allocation},
volume = {132},
journal = {Annals of Operations Research},
doi = {10.1023/B:ANOR.0000045281.41041.ed}
}

@misc{Palomar,
 author = {Palomar, Daniel},
 title = {Robust Optimization with Applications},
 url = {https://palomar.home.ece.ust.hk/ELEC5470_lectures/slides_robust_optim.pdf},
 lastchecked = {20.12.2030},
}

@Book{martin1989,
 author = {Martin, Peter},
 title = {The investor's guide to fidelity funds},
 publisher = {Wiley},
 year = {1989},
 address = {New York},
 isbn = {978-0471622581}
 }

@article{Ahmadi2017,
author = {Ahmadi Javid, Amir and Fallah, Malihe},
year = {2017},
month = {08},
pages = {},
title = {Portfolio optimization with entropic value-at-risk},
journal = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2019.02.007}
}

@article{Ahmadi2012,
author = {Ahmadi Javid, Amir},
year = {2012},
month = {12},
pages = {},
title = {Entropic Value-at-Risk: A new coherent risk measure},
volume = {155},
journal = {Journal of Optimization Theory and Applications},
doi = {10.1007/s10957-011-9968-2}
}

@article{WCheung,
author = {Cheung, Wing},
year = {2007},
month = {08},
pages = {},
title = {The Augmented Black-Litterman Model: A Ranking-Free Approach to Factor-Based Portfolio Construction and Beyond},
volume = {13},
journal = {Quantitative Finance},
doi = {10.2139/ssrn.1347648}
}

@article{Cajas1,
author = {Cajas, Dany},
year = {2021},
month = {12},
pages = {},
title = {Entropic Portfolio Optimization: a Disciplined Convex Programming Framework},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3792520}
}


@article{BLB,
author = {Kolm, Petter and Ritter, Gordon},
year = {2016},
month = {10},
pages = {},
title = {On the Bayesian Interpretation of Black-Litterman},
volume = {258},
journal = {European Journal of Operational Research},
doi = {10.1016/j.ejor.2016.10.027}
}

@article{Thorp,
author = {Thorp, Edward},
year = {2008},
month = {12},
pages = {},
title = {The Kelly Criterion in Blackjack, Sports Betting, and the Stock Market},
volume = {1},
isbn = {9780444508751},
journal = {Handbook of Asset and Liability Management},
doi = {10.1016/B978-044453248-0.50015-0}
}

@article{Cajas2,
author = {Cajas, Dany},
year = {2021},
month = {12},
pages = {},
title = {Kelly Portfolio Optimization: a Disciplined Convex Programming Framework},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3833617}
}


@mastersthesis{Sjostrand,
  author       = {Sj{\"o}strand, Daniel and Behnejad, Nima},
  title        = {Exploration of Hierarchical Clustering in Long-Only Risk-Based Portfolio Optimization},
  school       = {Copenhagen Business School},
  year         = 2020,
  address      = {Solbjerg Pl. 3, 2000 Frederiksberg, Denmark},
  month        = 5,
  url={https://research-api.cbs.dk/ws/portalfiles/portal/62178444/879726_Master_Thesis_Nima_Daniel_15736.pdf},
}

@article {Prado1,
	author = {López de Prado, Marcos},
	title = {Building Diversified Portfolios that Outperform Out of Sample},
	volume = {42},
	number = {4},
	pages = {59--69},
	year = {2016},
	doi = {10.3905/jpm.2016.42.4.059},
	publisher = {Institutional Investor Journals Umbrella},
	abstract = {In this article, the author introduces the Hierarchical Risk Parity (HRP) approach to address three major concerns of quadratic optimizers, in general, and Markowitz{\textquoteright}s critical line algorithm (CLA), in particular: instability, concentration, and underperformance. HRP applies modern mathematics (graph theory and machine-learning techniques) to build a diversified portfolio based on the information contained in the covariance matrix. However, unlike quadratic optimizers, HRP does not require the invertibility of the covariance matrix. In fact, HRP can compute a portfolio on an ill-degenerated or even a singular covariance matrix{\textemdash}an impossible feat for quadratic optimizers. Monte Carlo experiments show that HRP delivers lower out-ofsample variance than CLA, even though minimum variance is CLA{\textquoteright}s optimization objective. HRP also produces less risky portfolios out of sample compared to traditional risk parity methods.},
	issn = {0095-4918},
	URL = {https://jpm.pm-research.com/content/42/4/59},
	eprint = {https://jpm.pm-research.com/content/42/4/59.full.pdf},
	journal = {The Journal of Portfolio Management}
}

@misc{Raffinot2,
author = {Raffinot, Thomas},
year = {2018},
month = {08},
pages = {},
title = {The Hierarchical Equal Risk Contribution Portfolio},
doi = {10.2139/ssrn.3237540}
}

@article{twogap,
author = {Yue, Shihong and Wang, Xiuxiu and Wei, Miaomiao},
year = {2008},
month = {06},
pages = {217-221},
title = {Application of two-order difference to gap statistic},
volume = {14},
journal = {Transactions of Tianjin University},
doi = {10.1007/s12209-008-0039-1}
}

@article{Szekely,
author = {Gábor J. Székely and Maria L. Rizzo and Nail K. Bakirov},
title = {{Measuring and testing dependence by correlation of distances}},
volume = {35},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {2769 -- 2794},
keywords = {Distance correlation, distance covariance, multivariate independence},
year = {2007},
doi = {10.1214/009053607000000505},
URL = {https://doi.org/10.1214/009053607000000505}
}

@incollection{YUE2014949,
title = {Reformulation-linearization Method for Global Optimization of Mixed Integer Linear Fractional Programming Problems with Application on Sustainable Batch Scheduling},
editor = {Jiří Jaromír Klemeš and Petar Sabev Varbanov and Peng Yen Liew},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {33},
pages = {949-954},
year = {2014},
booktitle = {24th European Symposium on Computer Aided Process Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-444-63456-6.50159-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780444634566501599},
author = {Dajun Yue and Fengqi You},
keywords = {reformulation-linearization, mixed-integer linear fractional programming, MILFP, sustainable scheduling},
}

@article{Song,
    doi = {10.1371/journal.pone.0031929},
    author = {Song, Won-Min AND Di Matteo, T. AND Aste, Tomaso},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {Hierarchical Information Clustering by Means of Topologically Embedded Graphs},
    year = {2012},
    month = {03},
    volume = {7},
    url = {https://doi.org/10.1371/journal.pone.0031929},
    pages = {1-14},
    abstract = {We introduce a graph-theoretic approach to extract clusters and hierarchies in complex data-sets in an unsupervised and deterministic manner, without the use of any prior information. This is achieved by building topologically embedded networks containing the subset of most significant links and analyzing the network structure. For a planar embedding, this method provides both the intra-cluster hierarchy, which describes the way clusters are composed, and the inter-cluster hierarchy which describes how clusters gather together. We discuss performance, robustness and reliability of this method by first investigating several artificial data-sets, finding that it can outperform significantly other established approaches. Then we show that our method can successfully differentiate meaningful clusters and hierarchies in a variety of real data-sets. In particular, we find that the application to gene expression patterns of lymphoma samples uncovers biologically significant groups of genes which play key-roles in diagnosis, prognosis and treatment of some of the most relevant human lymphoid malignancies.},
    number = {3},
}

@article{Massara,
  title={Network Filtering for Big Data: Triangulated Maximally Filtered Graph},
  author={Guido Previde Massara and T. D. Matteo and T. Aste},
  journal={J. Complex Networks},
  year={2017},
  volume={5},
  pages={161-178}
}

@article{Song2,
title = {Nested hierarchies in planar graphs},
journal = {Discrete Applied Mathematics},
volume = {159},
number = {17},
pages = {2135-2146},
year = {2011},
issn = {0166-218X},
doi = {https://doi.org/10.1016/j.dam.2011.07.018},
url = {https://www.sciencedirect.com/science/article/pii/S0166218X11002794},
author = {Won-Min Song and T. {Di Matteo} and Tomaso Aste},
keywords = {Maximal planar graph, 3-clique, Bubble, Hierarchy, Community},
abstract = {We construct a partial order relation which acts on the set of 3-cliques of a maximal planar graph G and defines a unique hierarchy. We demonstrate that G is the union of a set of special subgraphs, named ‘bubbles’, that are themselves maximal planar graphs. The graph G is retrieved by connecting these bubbles in a tree structure where neighboring bubbles are joined together by a 3-clique. Bubbles naturally provide the subdivision of G into communities and the tree structure defines the hierarchical relations between these communities.}
}

@TechReport{Pfitzinger,
  author={Johann Pfitzinger and Nico Katzke},
  title={A constrained hierarchical risk parity algorithm with cluster-based capital allocation},
  year={2019},
  institution={Stellenbosch University, Department of Economics},
  type={Working Papers},
  url={https://ideas.repec.org/p/sza/wpaper/wpapers328.html},
  number={14/2019},
  abstract={Hierarchical Risk Parity (HRP) is a risk-based portfolio optimisation algorithm, which has been shown to generate diversified portfolios with robust out-of-sample properties without the need for a positive-definite return covariance matrix (Lopez de Prado 2016). The algorithm applies machine learning techniques to identify the underlying hierarchical correlation structure of the portfolio, allowing clusters of similar assets to compete for capital. The resulting allocation is both well-diversified over risk sources and intuitively appealing. This paper proposes a method of fully exploiting the information created by the clustering process, achieving enhanced out-of-sample risk and return characteristics. In addition, a practical approach to calculating HRP weights under box and group constraints is introduced. A comprehensive set of portfolio simulations over 6 equity universes demonstrates the appeal of the algorithm for portfolios consisting of 20 - 200 assets. HRP delivers highly diversified allocations with low volatility, low portfolio turnover and competitive performance metrics.},
  keywords={Risk Parity; Diversification; Portfolio Optimisation; Clustering},
  doi={},
}


@Article{GambetaKwon,
AUTHOR = {Gambeta, Vaughn and Kwon, Roy},
TITLE = {Risk Return Trade-Off in Relaxed Risk Parity Portfolio Optimization},
JOURNAL = {Journal of Risk and Financial Management},
VOLUME = {13},
YEAR = {2020},
NUMBER = {10},
ARTICLE-NUMBER = {237},
URL = {https://www.mdpi.com/1911-8074/13/10/237},
ISSN = {1911-8074},
ABSTRACT = {This paper formulates a relaxed risk parity optimization model to control the balance of risk parity violation against the total portfolio performance. Risk parity has been criticized as being overly conservative and it is improved by re-introducing the asset expected returns into the model and permitting the portfolio to violate the risk parity condition. This paper proposes the incorporation of an explicit target return goal with an intuitive target return approach into a second-order-cone model of a risk parity optimization. When the target return is greater than risk parity return, a violation to risk parity allocations occurs that is controlled using a computational construct to obtain near-risk parity portfolios to retain as much risk parity-like traits as possible. This model is used to demonstrate empirically that higher returns can be achieved than risk parity without the risk contributions deviating dramatically from the risk parity allocations. Furthermore, this study reveals that the relaxed risk parity model exhibits advantageous traits of robustness to expected returns, which should not deter the use of expected returns in risk parity model.},
DOI = {10.3390/jrfm13100237}
}

@TechReport{RichardRoncalli,
  author={Jean-Charles Richard and Thierry Roncalli},
  title={{Constrained Risk Budgeting Portfolios: Theory, Algorithms, Applications \& Puzzles}},
  year=2019,
  month=Feb,
  institution={arXiv.org},
  type={Papers},
  url={https://ideas.repec.org/p/arx/papers/1902.05710.html},
  number={1902.05710},
  abstract={This article develops the theory of risk budgeting portfolios, when we would like to impose weight constraints. It appears that the mathematical problem is more complex than the traditional risk budgeting problem. The formulation of the optimization program is particularly critical in order to determine the right risk budgeting portfolio. We also show that numerical solutions can be found using methods that are used in large-scale machine learning problems. Indeed, we develop an algorithm that mixes the method of cyclical coordinate descent (CCD), alternating direction method of multipliers (ADMM), proximal operators and Dykstra's algorithm. This theoretical body is then applied to some investment problems. In particular, we show how to dynamically control the turnover of a risk parity portfolio and how to build smart beta portfolios based on the ERC approach by improving the liquidity of the portfolio or reducing the small cap bias. Finally, we highlight the importance of the homogeneity property of risk measures and discuss the related scaling puzzle.},
  keywords={},
  doi={},
}

@article{Prado2,
author = {Prado, Marcos},
year = {2019},
month = {01},
pages = {},
title = {A Robust Estimator of the Efficient Frontier},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3469961}
}

@article{jLogo,
   title={Parsimonious modeling with information filtering networks},
   volume={94},
   ISSN={2470-0053},
   url={http://dx.doi.org/10.1103/PhysRevE.94.062306},
   DOI={10.1103/physreve.94.062306},
   number={6},
   journal={Physical Review E},
   publisher={American Physical Society (APS)},
   author={Barfuss, Wolfram and Massara, Guido Previde and Di Matteo, T. and Aste, Tomaso},
   year={2016},
   month={Dec} }

@book{MLforAM,
place={Cambridge},
series={Elements in Quantitative Finance},
title={Machine Learning for Asset Managers},
DOI={10.1017/9781108883658},
publisher={Cambridge University Press},
author={López de Prado, Marcos M.},
year={2020},
collection={Elements in Quantitative Finance}}

@article{Cajas3,
author = {Cajas, Dany},
year = {2021},
month = {12},
pages = {},
title = {OWA Portfolio Optimization: a Disciplined Convex Programming Framework},
journal = {SSRN Electronic Journal},
doi = {10.2139/ssrn.3988927}
}

@article{Yitzhaki1,
author = {Yitzhaki, Shlomo},
year = {1982},
month = {01},
pages = {178-85},
title = {Stochastic Dominance, Mean Variance, and Gini's Mean Difference},
volume = {72},
journal = {American Economic Review}
}

@article{Ogryczak2002,
author = {Ogryczak, W. and Ruszczynskia, Andrzej},
year = {2002},
month = {09},
pages = {661-680},
title = {Dual Stochastic Dominance and Quantile Risk Measures},
volume = {9},
journal = {International Transactions in Operational Research},
doi = {10.1111/1475-3995.00380}
}
